{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb4625da-a0cf-432d-b047-16cdd5195b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: U1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function mean at 0x0000023048099C60> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\U1000_Ahmedabad_Lead Day 1_daily basis.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function mean at 0x0000023048099C60> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\U1000_Ahmedabad_Lead Day 2_daily basis.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function mean at 0x0000023048099C60> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\U1000_Ahmedabad_Lead Day 3_daily basis.xlsx\n",
      "Processing: V1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function mean at 0x0000023048099C60> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\V1000_Ahmedabad_Lead Day 1_daily basis.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function mean at 0x0000023048099C60> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\V1000_Ahmedabad_Lead Day 2_daily basis.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function mean at 0x0000023048099C60> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\V1000_Ahmedabad_Lead Day 3_daily basis.xlsx\n",
      "Processing: PREC\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f015\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:156: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_temp.loc[time][0:25] = (np.ravel(data)*10800)\n",
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:154: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_temp.loc[time][0:25] = (np.ravel(data)*21600) - np.ravel(data_temp.loc[time_prev][0:25])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f021\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f024\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f027\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f030\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f033\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f036\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f039\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f042\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f045\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f048\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f051\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f054\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f057\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f060\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f063\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f066\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f069\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f072\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f075\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f078\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f081\n",
      "[INFO] Accessing file: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC\\gfs.20250727.t06z.pgrb2.0p25.f084\n",
      "\n",
      "[DEBUG] Raw data_prec before timezone shift and filtering:\n",
      "                          PREC_23.5_72.0_015 PREC_23.5_72.25_015  \\\n",
      "2025-07-27 06:00:00+00:00             0.3024             4.00896   \n",
      "\n",
      "                          PREC_23.5_72.5_015 PREC_23.5_72.75_015  \\\n",
      "2025-07-27 06:00:00+00:00             1.2528             4.76064   \n",
      "\n",
      "                          PREC_23.5_73.0_015 PREC_23.25_72.0_015  \\\n",
      "2025-07-27 06:00:00+00:00            1.73664              0.3024   \n",
      "\n",
      "                          PREC_23.25_72.25_015 PREC_23.25_72.5_015  \\\n",
      "2025-07-27 06:00:00+00:00              3.36096             0.82944   \n",
      "\n",
      "                          PREC_23.25_72.75_015 PREC_23.25_73.0_015  ...  \\\n",
      "2025-07-27 06:00:00+00:00              0.38016             1.61568  ...   \n",
      "\n",
      "                          PREC_22.75_72.0_084 PREC_22.75_72.25_084  \\\n",
      "2025-07-27 06:00:00+00:00             0.06048             -0.09504   \n",
      "\n",
      "                          PREC_22.75_72.5_084 PREC_22.75_72.75_084  \\\n",
      "2025-07-27 06:00:00+00:00             -0.0864             -0.09504   \n",
      "\n",
      "                          PREC_22.75_73.0_084 PREC_22.5_72.0_084  \\\n",
      "2025-07-27 06:00:00+00:00            -0.01728            0.03456   \n",
      "\n",
      "                          PREC_22.5_72.25_084 PREC_22.5_72.5_084  \\\n",
      "2025-07-27 06:00:00+00:00             0.01728           -0.26784   \n",
      "\n",
      "                          PREC_22.5_72.75_084 PREC_22.5_73.0_084  \n",
      "2025-07-27 06:00:00+00:00            -0.10368            0.06048  \n",
      "\n",
      "[1 rows x 600 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:161: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_prec.loc[time_step][0:600] = np.ravel(data_temp)\n",
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function sum at 0x0000023048098B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC_Ahmedabad_Lead Day 1_daily basis.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function sum at 0x0000023048098B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC_Ahmedabad_Lead Day 2_daily basis.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\AppData\\Local\\Temp\\ipykernel_11664\\1101289331.py:206: FutureWarning: The provided callable <function sum at 0x0000023048098B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved to: C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\\PREC_Ahmedabad_Lead Day 3_daily basis.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygrib\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# ---------------------------- CONFIG ---------------------------- #\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\Angshudeep Majumdar\\Downloads\\Githubs_Code_RUVISION_Final\"\n",
    "LAT_BOUNDS = [22.25, 23.5]\n",
    "LON_BOUNDS = [72.0, 73.25]\n",
    "FORECAST_HOURS = list(range(15, 85, 3))\n",
    "GRID_SIZE = 25\n",
    "INIT_TIMES = [6]\n",
    "VARIABLES = ['U1000', 'V1000', 'PREC']\n",
    "\n",
    "# ---------------------- UTILITY FUNCTIONS ----------------------- #\n",
    "\n",
    "def create_output_folder(variable):\n",
    "    path = os.path.join(BASE_PATH, variable)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def generate_url(current_date, init_hour, forecast_hour, variable):\n",
    "    base_url = \"https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl\"\n",
    "    var_flags = {\n",
    "        \"U1000\": \"var_UGRD=on&lev_1000_mb=on\",\n",
    "        \"V1000\": \"var_VGRD=on&lev_1000_mb=on\",\n",
    "        \"PREC\": \"var_PRATE=on&lev_surface=on\"\n",
    "    }\n",
    "    var_flag = var_flags[variable]\n",
    "    return (\n",
    "        f\"{base_url}?dir=%2Fgfs.{current_date.strftime('%Y%m%d')}%2F{init_hour:02d}%2Fatmos&\"\n",
    "        f\"file=gfs.t{init_hour:02d}z.pgrb2.0p25.f{forecast_hour:03d}&{var_flag}&\"\n",
    "        f\"subregion=&toplat=74&leftlon=22&rightlon=24&bottomlat=72\"\n",
    "    )\n",
    "\n",
    "def download_grib_files(variable):\n",
    "    output_dir = create_output_folder(variable)\n",
    "    current_date= datetime.now(timezone.utc)\n",
    "    #current_date = datetime.now(timezone.utc) - timedelta(days=1)\n",
    "\n",
    "    for init_time in INIT_TIMES:\n",
    "        for fh in FORECAST_HOURS:\n",
    "            url = generate_url(current_date, init_time, fh, variable)\n",
    "            filename = f\"gfs.{current_date.strftime('%Y%m%d')}.t{init_time:02d}z.pgrb2.0p25.f{fh:03d}\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "            if not os.path.exists(filepath):\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(response.content)\n",
    "                    print(f\"Downloaded: {filename}\")\n",
    "                else:\n",
    "                    print(f\"Failed to download ({response.status_code}): {url}\")\n",
    "\n",
    "    return output_dir\n",
    "\n",
    "def extract_data_grid(filepath, variable):\n",
    "    try:\n",
    "        fh = int(re.search(r'f(\\d{3})$', filepath).group(1))\n",
    "        grbs = pygrib.open(filepath)\n",
    "        var_name_map = {\n",
    "            \"U1000\": \"U component of wind\",\n",
    "            \"V1000\": \"V component of wind\",\n",
    "        }\n",
    "        grb = grbs.select(name=var_name_map[variable])[0]\n",
    "        data = grb.values\n",
    "        grbs.close()\n",
    "\n",
    "        grid = data[2:7, 2:7][::-1]\n",
    "        flat = np.ravel(grid)\n",
    "        return flat\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to extract data from {filepath}: {e}\")\n",
    "        return np.full(GRID_SIZE, np.nan)\n",
    "\n",
    "def preprocess_wind(variable, directory):\n",
    "    ts_utc = pd.Timestamp.utcnow().normalize() + pd.Timedelta(hours=6)\n",
    "    #ts_utc = pd.Timestamp.utcnow().normalize()- pd.Timedelta(days=1) + pd.Timedelta(hours=6)\n",
    "    \n",
    "    df = pd.DataFrame(index=[ts_utc], columns=[f\"{variable}_{lat}_{lon}_{fh:03d}\"\n",
    "                                               for fh in FORECAST_HOURS\n",
    "                                               for lat in np.arange(23.5, 22.25, -0.25)\n",
    "                                               for lon in np.arange(72.0, 73.25, 0.25)])\n",
    "\n",
    "    for fh in FORECAST_HOURS:\n",
    "        filename = f\"gfs.{ts_utc.strftime('%Y%m%d')}.t06z.pgrb2.0p25.f{fh:03d}\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        flat = extract_data_grid(filepath, variable)\n",
    "        if flat.shape[0] == GRID_SIZE:\n",
    "            for i, val in enumerate(flat):\n",
    "                df.iloc[0, i + (FORECAST_HOURS.index(fh) * GRID_SIZE)] = val\n",
    "\n",
    "    df = df.shift(freq=pd.Timedelta(hours=5, minutes=30))\n",
    "    df.index.name = 'DateTime'\n",
    "    df = df[df.index.time == pd.Timestamp(\"11:30\").time()]\n",
    "    return split_and_reshape_data(df, variable)\n",
    "\n",
    "\n",
    "def preprocess_precipitation(variable, directory):\n",
    "    latbounds = LAT_BOUNDS\n",
    "    lonbounds = LON_BOUNDS\n",
    "    time_from_ref = FORECAST_HOURS\n",
    "\n",
    "    ts_06utc = pd.Timestamp.utcnow().normalize() + pd.Timedelta(hours=6)\n",
    "    #ts_06utc = pd.Timestamp.utcnow().normalize() - pd.Timedelta(days=1) + pd.Timedelta(hours=6)\n",
    "    \n",
    "    data_prec = pd.DataFrame(index=[ts_06utc], columns=[\n",
    "        f\"{variable}_{j}_{k}_{t:03d}\"\n",
    "        for t in time_from_ref\n",
    "        for j in np.arange(23.5, 22.25, -0.25)\n",
    "        for k in np.arange(72.0, 73.25, 0.25)\n",
    "    ])\n",
    "\n",
    "    counter = 0  # add counter if needed\n",
    "\n",
    "    for time_step in data_prec.index:\n",
    "        year = time_step.year\n",
    "        month = time_step.month\n",
    "        day = time_step.day\n",
    "        ref_time = time_step.hour\n",
    "\n",
    "        date_temp = pd.date_range(start=time_step + timedelta(hours=15),\n",
    "                              end=time_step + timedelta(hours=84), freq='3h')\n",
    "        data_temp = pd.DataFrame(index=date_temp, columns=np.arange(25))\n",
    "\n",
    "        for time_lag in time_from_ref:\n",
    "            filename = f'gfs.{year}{month:02d}{day:02d}.t{ref_time:02d}z.pgrb2.0p25.f{time_lag:03d}'\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            print(f\"[INFO] Accessing file: {filepath}\")  # 👈 This line will print the full path\n",
    "\n",
    "            try:\n",
    "                grbs = pygrib.open(filepath)\n",
    "                grb = grbs.select(name='Precipitation rate')[0]\n",
    "                temp = grb.values\n",
    "                lats, lons = grb.latlons()\n",
    "                lats_reshaped = lats[:,0]  # Reshape latitudes to (189,)\n",
    "                reversed_arr = lats_reshaped[::-1]\n",
    "                lons_reshaped = lons[0,:]  # Reshape longitudes to (,201)\n",
    "                lats=reversed_arr\n",
    "                lons=lons_reshaped\n",
    "\n",
    "                # latitude lower and upper index\n",
    "            latli = np.argmin( np.abs( reversed_arr - latbounds[1] ) )\n",
    "            latui = np.argmin( np.abs( reversed_arr - latbounds[0] ) ) \n",
    "\n",
    "            # longitude lower and upper index\n",
    "            lonli = np.argmin( np.abs( lons_reshaped- lonbounds[0] ) )\n",
    "            lonui = np.argmin( np.abs( lons_reshaped - lonbounds[1] ) )  \n",
    "\n",
    "                data = temp[latli:latui, lonli:lonui][::-1]\n",
    "                time = time_step + timedelta(hours=int(time_lag))\n",
    "                time_prev = time - timedelta(hours=3)\n",
    "\n",
    "                if data.size == 25:\n",
    "                    if time_lag % 6 == 0:\n",
    "                        if time_prev in data_temp.index:\n",
    "                            data_temp.loc[time][0:25] = (np.ravel(data)*21600) - np.ravel(data_temp.loc[time_prev][0:25])\n",
    "                    elif time_lag % 3 == 0:\n",
    "                        data_temp.loc[time][0:25] = (np.ravel(data)*10800)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {filename}: {e}\")\n",
    "\n",
    "        data_prec.loc[time_step][0:600] = np.ravel(data_temp)\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:\n",
    "            print(f'Loop {counter} Done!')\n",
    "\n",
    "    print(\"\\n[DEBUG] Raw data_prec before timezone shift and filtering:\")\n",
    "    print(data_prec)\n",
    "\n",
    "    data_prec = data_prec.shift(freq=pd.Timedelta(hours=5, minutes=30))\n",
    "    data_prec.index.name = 'DateTime'\n",
    "    extracted = data_prec[data_prec.index.time == pd.Timestamp(\"11:30\").time()]\n",
    "    \n",
    "    return split_and_reshape_data(extracted, variable)\n",
    "\n",
    "\n",
    "def split_and_reshape_data(df, variable):\n",
    "    ranges = {\n",
    "        1: list(range(15, 37, 3)),\n",
    "        2: list(range(39, 61, 3)),\n",
    "        3: list(range(63, 85, 3))\n",
    "    }\n",
    "    outputs = {}\n",
    "    for day, steps in ranges.items():\n",
    "        cols = ~df.columns.str.contains('|'.join([f\"{x:03d}\" for x in FORECAST_HOURS if x not in steps]))\n",
    "        day_df = df.loc[:, cols]\n",
    "        chunks = [day_df.iloc[:, i:i + 25].values for i in range(0, day_df.shape[1], 25)]\n",
    "        base_time = df.index[0] + pd.Timedelta(hours=min(steps))\n",
    "        timestamps = pd.date_range(start=base_time, periods=8, freq='3h')\n",
    "        result = pd.DataFrame(index=timestamps, columns=[f\"{variable}_{i}\" for i in range(25)])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            result.iloc[i] = chunk[0]\n",
    "        outputs[day] = result\n",
    "    return outputs\n",
    "\n",
    "def aggregate_and_save(daily_data, variable):\n",
    "    today = pd.Timestamp.today().normalize()\n",
    "    #today = pd.Timestamp.today().normalize() - pd.Timedelta(days=1)\n",
    "    \n",
    "    targets = {\n",
    "        1: today + pd.Timedelta(days=1, hours=23, minutes=30),\n",
    "        2: today + pd.Timedelta(days=2, hours=23, minutes=30),\n",
    "        3: today + pd.Timedelta(days=3, hours=23, minutes=30),\n",
    "    }\n",
    "\n",
    "    for day, df in daily_data.items():\n",
    "        agg_func = np.sum if variable == \"PREC\" else np.mean\n",
    "        grouped = df.groupby(df.index.to_series().reset_index(drop=True).index // 8).agg(agg_func)\n",
    "        grouped.index = [targets[day]]\n",
    "        grouped.index.name = \"DateTime\"\n",
    "\n",
    "        filename = os.path.join(BASE_PATH, f\"{variable}_Ahmedabad_Lead Day {day}_daily basis.xlsx\")\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                old_df = pd.read_excel(filename, index_col='DateTime', parse_dates=True)\n",
    "                grouped.columns = old_df.columns\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Could not read or align existing file: {e}\")\n",
    "                old_df = pd.DataFrame(columns=grouped.columns)\n",
    "        else:\n",
    "            old_df = pd.DataFrame(columns=grouped.columns)\n",
    "\n",
    "        combined = pd.concat([old_df, grouped])\n",
    "        combined = combined[~combined.index.duplicated(keep='last')]\n",
    "\n",
    "        combined.to_excel(filename)\n",
    "        print(f\"[INFO] Saved to: {filename}\")\n",
    "\n",
    "# ---------------------- MAIN EXECUTION ----------------------- #\n",
    "\n",
    "def preprocess_variable(variable, directory):\n",
    "    if variable == \"PREC\":\n",
    "        return preprocess_precipitation(variable, directory)\n",
    "    else:\n",
    "        return preprocess_wind(variable, directory)\n",
    "\n",
    "def main():\n",
    "    for variable in VARIABLES:\n",
    "        print(f\"Processing: {variable}\")\n",
    "        output_dir = download_grib_files(variable)\n",
    "        daily_data = preprocess_variable(variable, output_dir)\n",
    "        aggregate_and_save(daily_data, variable)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d1466-2718-4841-95b2-7b9aeed80e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
